project_id: my-ai-system-20260214-234250
generated_at: '2026-02-14T23:42:50.268763+00:00'
items:
- item_id: 73ac85a7334f693d
  merge_key: CTRL-GOV-0100
  canonical_id: CTRL-GOV-0100
  title: Classify AI system risk level and role (provider/deployer)
  objective: Determine whether the system is prohibited, high-risk, subject to transparency
    obligations, or minimal risk.
  severity: high
  category: EU AI Act - Scoping
  domain: governance
  pack_refs:
  - domain: governance
    pack_id: eu-ai-act
    version: 2024-1689
    control_id: EU-HR-01
    source:
      name: European Union
      reference: Regulation (EU) 2024/1689 (AI Act)
      url: https://eur-lex.europa.eu/
    pack_hash: 3926677948d6939d3a6cf4a048f4f82f7c8594107345fe04b7e710d87e8d6af2
  why_applies: 'Triggered by: EU in jurisdiction.list (resolved ''EU'' in [''US'',
    ''EU'', ''UK'', ''CA'', ''SG''])'
  evidence_required:
  - type: record
    name: EU AI Act scoping memo (risk level + role)
  test_procedures:
  - Verify documented classification and rationale, including system intended use.
  status: not_started
  owner: null
  notes: null
  evidence: []
- item_id: bd7f42ad18edce58
  merge_key: CTRL-GOV-0001
  canonical_id: CTRL-GOV-0001
  title: Define AI roles, responsibilities, and approval gates
  objective: Establish ownership, decision rights, and escalation for the AI system
    lifecycle.
  severity: high
  category: GOVERN
  domain: governance
  pack_refs:
  - domain: governance
    pack_id: nist-ai-rmf
    version: '1.0'
    control_id: GOV01
    source:
      name: NIST
      reference: NIST AI Risk Management Framework 1.0
      url: https://www.nist.gov/itl/ai-risk-management-framework
    pack_hash: 3fd433cca1373150657d03473f97128f7bc04419c90408687ad9380dec8624e9
  why_applies: 'Triggered by: exists(system.name)'
  evidence_required:
  - type: policy
    name: AI governance policy / RACI
  - type: record
    name: Approval gates definition (design → launch → change)
  test_procedures:
  - Verify named owners exist for model, data, security, and risk decisions.
  status: not_started
  owner: null
  notes: null
  evidence: []
- item_id: 74d5f04452933947
  merge_key: CTRL-GOV-0002
  canonical_id: CTRL-GOV-0002
  title: Maintain evaluation plan for performance, robustness, and safety
  objective: Define and run evaluations appropriate to the use case risk profile.
  severity: high
  category: MEASURE
  domain: governance
  pack_refs:
  - domain: governance
    pack_id: nist-ai-rmf
    version: '1.0'
    control_id: MEASURE01
    source:
      name: NIST
      reference: NIST AI Risk Management Framework 1.0
      url: https://www.nist.gov/itl/ai-risk-management-framework
    pack_hash: 3fd433cca1373150657d03473f97128f7bc04419c90408687ad9380dec8624e9
  why_applies: 'Triggered by: exists(system.name)'
  evidence_required:
  - type: plan
    name: Evaluation plan (metrics, datasets, thresholds)
  - type: test_report
    name: Evaluation results & sign-off
  test_procedures:
  - Confirm evaluation covers relevant harms (e.g., bias, hallucination, robustness).
  - Confirm thresholds and go/no-go criteria are defined.
  status: not_started
  owner: null
  notes: null
  evidence: []
- item_id: accb47df12224432
  merge_key: CTRL-SAF-0002
  canonical_id: CTRL-SAF-0002
  title: Maintain a Dataset Sheet for key training/retrieval datasets
  objective: Document dataset sources, access, transformations, and risks.
  severity: medium
  category: Documentation
  domain: safety
  pack_refs:
  - domain: safety
    pack_id: model-documentation
    version: '1.0'
    control_id: DOC02
    source:
      name: Community
      reference: Documentation best practices for AI systems (model/system/dataset
        docs)
      url: null
    pack_hash: a2c9a235f61e9c908302b859a46d753d717f6edc351b4e6c05c21b4f6c821428
  why_applies: 'Triggered by: pattern.rag == True (resolved True == True)'
  evidence_required:
  - type: document
    name: Dataset Sheet(s)
  test_procedures:
  - Validate dataset sheets include provenance, consent/license checks, and retention.
  status: not_started
  owner: null
  notes: null
  evidence: []
- item_id: 1404653f95e0f4be
  merge_key: CTRL-SAF-0001
  canonical_id: CTRL-SAF-0001
  title: Maintain a System Card for the AI system
  objective: Capture intended use, capabilities, limitations, safety mitigations,
    and monitoring.
  severity: medium
  category: Documentation
  domain: safety
  pack_refs:
  - domain: safety
    pack_id: model-documentation
    version: '1.0'
    control_id: DOC01
    source:
      name: Community
      reference: Documentation best practices for AI systems (model/system/dataset
        docs)
      url: null
    pack_hash: a2c9a235f61e9c908302b859a46d753d717f6edc351b4e6c05c21b4f6c821428
  why_applies: 'Triggered by: exists(system.name)'
  evidence_required:
  - type: document
    name: System Card (approved)
  test_procedures:
  - Confirm system card includes intended use, limitations, known failure modes, and
    escalation paths.
  status: not_started
  owner: null
  notes: null
  evidence: []
- item_id: e655ebbfecb17276
  merge_key: CTRL-SEC-0006
  canonical_id: CTRL-SEC-0006
  title: Sensitive data exposure controls (PII/PHI)
  objective: Prevent the model from disclosing sensitive data in prompts, logs, and
    outputs.
  severity: critical
  category: Data protection
  domain: security
  pack_refs:
  - domain: security
    pack_id: owasp-llm-top10
    version: '1.1'
    control_id: LLM06
    source:
      name: OWASP
      reference: OWASP Top 10 for Large Language Model Applications (v1.1)
      url: https://owasp.org/www-project-top-10-for-large-language-model-applications/
    pack_hash: 9024d224ff922a2ab23f16f4447c004047cb42f2c3bd3b21e387113a05305db0
  why_applies: 'Triggered by: data.pii == True (resolved True == True)'
  evidence_required:
  - type: policy
    name: Data handling & logging policy for LLM apps
  - type: config
    name: Redaction/filters configuration
  test_procedures:
  - Verify PII/PHI redaction in prompts, outputs, and logs.
  - Validate access controls for traces and conversation logs.
  status: not_started
  owner: null
  notes: null
  evidence: []
- item_id: 45c6fd0c284c287d
  merge_key: CTRL-SEC-0001
  canonical_id: CTRL-SEC-0001
  title: Prompt injection defenses
  objective: Prevent untrusted inputs from overriding system instructions or tool
    policies.
  severity: high
  category: Input & instruction integrity
  domain: security
  pack_refs:
  - domain: security
    pack_id: owasp-llm-top10
    version: '1.1'
    control_id: LLM01
    source:
      name: OWASP
      reference: OWASP Top 10 for Large Language Model Applications (v1.1)
      url: https://owasp.org/www-project-top-10-for-large-language-model-applications/
    pack_hash: 9024d224ff922a2ab23f16f4447c004047cb42f2c3bd3b21e387113a05305db0
  why_applies: 'Most LLM applications accept untrusted input that can manipulate behavior
    or tool use.

    Triggered by: has_tag(llm)'
  evidence_required:
  - type: design_doc
    name: Prompt boundary design + threat model
  - type: test_report
    name: Prompt injection evaluation results
  test_procedures:
  - Run a prompt-injection test suite against representative prompts.
  - Verify system message isolation and tool-call allowlisting.
  status: not_started
  owner: null
  notes: null
  evidence: []
- item_id: 52a463537b216287
  merge_key: CTRL-SEC-0002
  canonical_id: CTRL-SEC-0002
  title: Training data / RAG data poisoning protections
  objective: Reduce risk of poisoning in training data, embeddings, and retrieval
    corpora.
  severity: high
  category: Data integrity
  domain: security
  pack_refs:
  - domain: security
    pack_id: owasp-llm-top10
    version: '1.1'
    control_id: LLM02
    source:
      name: OWASP
      reference: OWASP Top 10 for Large Language Model Applications (v1.1)
      url: https://owasp.org/www-project-top-10-for-large-language-model-applications/
    pack_hash: 9024d224ff922a2ab23f16f4447c004047cb42f2c3bd3b21e387113a05305db0
  why_applies: 'Triggered by: has_tag(rag)'
  evidence_required:
  - type: procedure
    name: Data curation + provenance procedure
  - type: test_report
    name: RAG corpus integrity checks / sampling results
  test_procedures:
  - Validate ingestion pipeline has provenance, access controls, and change review.
  - Spot-check retrieval corpus for malicious or policy-violating content.
  status: not_started
  owner: null
  notes: null
  evidence: []
counts:
  total: 8
  by_domain:
    governance: 3
    safety: 2
    security: 3
  by_status:
    not_started: 8
